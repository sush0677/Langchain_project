{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHwQ+R7vwMQbTE0f8uSK/D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sush0677/Langchain_project/blob/main/Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jzby6Ar-oJmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc761bd5-c0a8-4ce2-8787-0ea1d3fcccf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.17.0-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/268.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.17.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement azure-ai-openai (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for azure-ai-openai\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain_openai)\n",
            "  Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.17.0)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading langsmith-0.1.45-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.2/104.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.6.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, tiktoken, jsonpatch, langsmith, langchain-core, langchain_openai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.42 langchain_openai-0.1.3 langsmith-0.1.45 orjson-3.10.0 packaging-23.2 tiktoken-0.6.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.42)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.45)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 langchain-0.1.16 langchain-community-0.0.32 langchain-text-splitters-0.0.1 marshmallow-3.21.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting azure.identity\n",
            "  Downloading azure_identity-1.16.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.1/166.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core>=1.23.0 (from azure.identity)\n",
            "  Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure.identity) (42.0.5)\n",
            "Collecting msal>=1.24.0 (from azure.identity)\n",
            "  Downloading msal-1.28.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msal-extensions>=0.3.0 (from azure.identity)\n",
            "  Downloading msal_extensions-1.1.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.23.0->azure.identity) (2.31.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.23.0->azure.identity) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.23.0->azure.identity) (4.11.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.5->azure.identity) (1.16.0)\n",
            "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/lib/python3/dist-packages (from msal>=1.24.0->azure.identity) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from msal-extensions>=0.3.0->azure.identity) (23.2)\n",
            "Collecting portalocker<3,>=1.0 (from msal-extensions>=0.3.0->azure.identity)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.5->azure.identity) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.23.0->azure.identity) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.23.0->azure.identity) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.23.0->azure.identity) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.23.0->azure.identity) (2024.2.2)\n",
            "Installing collected packages: portalocker, azure-core, msal, msal-extensions, azure.identity\n",
            "Successfully installed azure-core-1.30.1 azure.identity-1.16.0 msal-1.28.0 msal-extensions-1.1.0 portalocker-2.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install azure-ai-openai\n",
        "!pip install langchain_openai\n",
        "!pip install langchain\n",
        "!pip install azure.identity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Get the Azure Credential\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Set the API type to `azure_ad`\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure_ad\""
      ],
      "metadata": {
        "id": "kt26bZM0p52v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import ChainedTokenCredential, ManagedIdentityCredential, AzureCliCredential\n",
        "\n",
        "credential = ChainedTokenCredential(\n",
        "    ManagedIdentityCredential(),\n",
        "    AzureCliCredential()\n",
        ")"
      ],
      "metadata": {
        "id": "rfBymZWxob8J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-02-15-preview\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://exquitech-openai-2.openai.azure.com/\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"4f00a70876a542a18b30f13570248cdb\""
      ],
      "metadata": {
        "id": "iSzKApbXohPQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Azure OpenAI\n",
        "from langchain_openai import AzureOpenAI\n",
        "\n",
        "# Create an instance of Azure OpenAI\n",
        "# Replace the deployment name with your own\n",
        "llm = AzureOpenAI(deployment_name=\"exq-gpt-35\", azure_endpoint = \"https://exquitech-openai-2.openai.azure.com/\" ,api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), temperature=0, openai_api_version=\"2024-02-15-preview\")\n",
        "\n",
        "# Run the LLM\n",
        "llm.invoke(\"Tell me a joke\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "t38E1jikri1H",
        "outputId": "d37cefe7-119b-4229-cc85-5fd70be4d43b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\".\\n\\nWhy did the tomato turn red?\\n\\nWhy?\\n\\nBecause it saw the salad dressing.\\n\\nThat's a good one. (laughing)\\n\\nI'm glad you liked it.\\n\\nI did.\\n\\nAll right, well, I'm gonna go now, but it was really nice talking to you.\\n\\nIt was nice talking to you too.\\n\\nAll right, bye.\\n\\nBye. (phone beeping)\\n\\nThat was a good one. (laughing) That was a good one. (laughing) That was a good one. (laughing) That was a good one. (laughing) That was a good one. (laughing) That was a good one. (laughing) That was a good one. (laughing) That was a good one. (laughing) That was a good one. (laughing) That was a good one. (laughing) That was a good one. (laughing)\\n\\nI'm sorry, I'm sorry. (laughing)\\n\\nI'm sorry, I'm sorry. (laughing)\\n\\nI'm sorry, I'm sorry. (laughing)\\n\\nI'm sorry, I'm sorry. (laughing)\\n\\nI'm sorry,\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm)\n",
        "llm.generate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "DyL6OTvCr5ym",
        "outputId": "c102137d-9db3-4d4c-f72a-4b6ca9a87f06"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mAzureOpenAI\u001b[0m\n",
            "Params: {'deployment_name': 'exq-gpt-35', 'model_name': 'gpt-3.5-turbo-instruct', 'temperature': 0.0, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 256}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseLLM.generate of AzureOpenAI(client=<openai.resources.completions.Completions object at 0x787400a5be20>, async_client=<openai.resources.completions.AsyncCompletions object at 0x787400a8dba0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='', azure_endpoint='https://exquitech-openai-2.openai.azure.com/', deployment_name='exq-gpt-35', openai_api_version='2024-02-15-preview', openai_api_type='azure_ad')>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.language_models.llms.BaseLLM.generate</b><br/>def generate(prompts: List[str], stop: Optional[List[str]]=None, callbacks: Optional[Union[Callbacks, List[Callbacks]]]=None, *, tags: Optional[Union[List[str], List[List[str]]]]=None, metadata: Optional[Union[Dict[str, Any], List[Dict[str, Any]]]]=None, run_name: Optional[Union[str, List[str]]]=None, run_id: Optional[Union[uuid.UUID, List[Optional[uuid.UUID]]]]=None, **kwargs: Any) -&gt; LLMResult</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py</a>Pass a sequence of prompts to a model and return generations.\n",
              "\n",
              "This method should make use of batched calls for models that expose a batched\n",
              "API.\n",
              "\n",
              "Use this method when you want to:\n",
              "    1. take advantage of batched calls,\n",
              "    2. need more output from the model than just the top generated value,\n",
              "    3. are building chains that are agnostic to the underlying language model\n",
              "        type (e.g., pure text completion models vs chat models).\n",
              "\n",
              "Args:\n",
              "    prompts: List of string prompts.\n",
              "    stop: Stop words to use when generating. Model output is cut off at the\n",
              "        first occurrence of any of these substrings.\n",
              "    callbacks: Callbacks to pass through. Used for executing additional\n",
              "        functionality, such as logging or streaming, throughout generation.\n",
              "    **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
              "        to the model provider API call.\n",
              "\n",
              "Returns:\n",
              "    An LLMResult, which contains a list of candidate Generations for each input\n",
              "        prompt and additional model provider-specific output.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 644);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AzureChatOpenAI**"
      ],
      "metadata": {
        "id": "yCZVSyBMw69R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_openai import AzureChatOpenAI"
      ],
      "metadata": {
        "id": "r7m2QGKmw7Xk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"4f00a70876a542a18b30f13570248cdb\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://exquitech-openai-2.openai.azure.com/\""
      ],
      "metadata": {
        "id": "g0I7iOWcxD45"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AzureChatOpenAI(deployment_name=\"exq-gpt-35\", azure_endpoint = \"https://exquitech-openai-2.openai.azure.com/\" ,api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), temperature=0, openai_api_version=\"2024-02-15-preview\")"
      ],
      "metadata": {
        "id": "HEgZ7nP_xVMG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompt Template**"
      ],
      "metadata": {
        "id": "b0-PMfka1RWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "q8FrcX0-1b9f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_input_prompt = PromptTemplate(input_variables=[\"topic\"],\n",
        "                                     template='Tell me a fact abot {topic}')\n",
        "llm(single_input_prompt.format(topic='sea'))"
      ],
      "metadata": {
        "id": "PAE4qckt2Ios",
        "outputId": "bc96d16b-c6b7-424f-896e-0d4d13948081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" otters.\\n\\nSea otters are the only marine mammals that use tools. They use rocks to break open the shells of their prey, such as clams and mussels.\\n\\nWhat is the largest animal in the world?\\n\\nThe blue whale is the largest animal in the world. It can grow up to 100 feet long and weigh as much as 200 tons.\\n\\nWhat is the smallest mammal in the world?\\n\\nThe bumblebee bat, also known as Kitti's hog-nosed bat, is the smallest mammal in the world. It weighs less than a penny and can fit on a human fingertip.\\n\\nWhat is the fastest land animal?\\n\\nThe cheetah is the fastest land animal, capable of running up to 70 miles per hour.\\n\\nWhat is the largest bird in the world?\\n\\nThe ostrich is the largest bird in the world. It can grow up to 9 feet tall and weigh as much as 350 pounds.\\n\\nWhat is the smallest bird in the world?\\n\\nThe bee hummingbird is the smallest bird in the world. It is only 2.25 inches long and weighs less than a penny.\\n\\nWhat is the largest reptile in the world?\\n\\nThe saltwater crocodile is the largest reptile in the world. It can grow up to\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "system_template=\"You are an AI recipe assistant that specializes in {dietary_preference} dishes that can be prepared in {cooking_time}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "system_message_prompt.input_variables\n",
        "human_template=\"{recipe_request}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ],
      "metadata": {
        "id": "ox3psVy4VLYH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "# get a chat completion from the formatted messages\n",
        "chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YEaE5hGWhuo",
        "outputId": "60248d0f-71f1-45e8-c013-20eac33aaca5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are an AI recipe assistant that specializes in Vegan dishes that can be prepared in 15 min.'),\n",
              " HumanMessage(content='Quick Snack')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "request = chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()\n",
        "result = model(request)\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHqDH4ydWtOo",
        "outputId": "e0d15a28-018b-4894-8aee-3edea695e6f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a quick and easy vegan snack recipe that can be prepared in just 15 minutes:\n",
            "\n",
            "Vegan Avocado Toast\n",
            "\n",
            "Ingredients:\n",
            "- 1 ripe avocado\n",
            "- 2 slices of bread\n",
            "- 1/2 lemon\n",
            "- Salt and pepper to taste\n",
            "- Optional toppings: sliced tomatoes, red pepper flakes, hemp seeds, or nutritional yeast\n",
            "\n",
            "Instructions:\n",
            "1. Toast the bread slices in a toaster or on a pan until crispy.\n",
            "2. While the bread is toasting, cut the avocado in half and remove the pit. Scoop out the flesh into a bowl and mash it with a fork.\n",
            "3. Squeeze the lemon juice over the mashed avocado and mix well.\n",
            "4. Season with salt and pepper to taste.\n",
            "5. Spread the avocado mixture evenly over the toasted bread slices.\n",
            "6. Add any desired toppings, such as sliced tomatoes, red pepper flakes, hemp seeds, or nutritional yeast.\n",
            "7. Serve immediately and enjoy your delicious vegan avocado toast!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Document Transformation**"
      ],
      "metadata": {
        "id": "U8mRA7uoJ6Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "with open('FDR_State_of_Union_1944.txt') as file:\n",
        "    speech_text = file.read()\n",
        "\n",
        "len(speech_text)\n",
        "\n",
        "len(speech_text.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZQzCpslJ6tu",
        "outputId": "ff32287f-a84e-4261-fe05-6ac61d64b7c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3750"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\",chunk_size=1000)\n",
        "\n",
        "texts = text_splitter.create_documents([speech_text])\n",
        "\n",
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlpO5eWjLYS_",
        "outputId": "da8b3a81-2873-496a-e2eb-67ec2c866fdf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"This Nation in the past two years has become an active partner in the world's greatest war against human slavery.\\n\\nWe have joined with like-minded people in order to defend ourselves in a world that has been gravely threatened with gangster rule.\\n\\nBut I do not think that any of us Americans can be content with mere survival. Sacrifices that we and our allies are making impose upon us all a sacred obligation to see to it that out of this war we and our children will gain something better than mere survival.\\n\\nWe are united in determination that this war shall not be followed by another interim which leads to new disaster- that we shall not repeat the tragic errors of ostrich isolationism—that we shall not repeat the excesses of the wild twenties when this Nation went for a joy ride on a roller coaster which ended in a tragic crash.\")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speech_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "Tg-HAnTrMBs_",
        "outputId": "cf5d9e6b-78a2-4816-ad1b-f7c7082b3f6e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This Nation in the past two years has become an active partner in the world\\'s greatest war against human slavery.\\n\\nWe have joined with like-minded people in order to defend ourselves in a world that has been gravely threatened with gangster rule.\\n\\nBut I do not think that any of us Americans can be content with mere survival. Sacrifices that we and our allies are making impose upon us all a sacred obligation to see to it that out of this war we and our children will gain something better than mere survival.\\n\\nWe are united in determination that this war shall not be followed by another interim which leads to new disaster- that we shall not repeat the tragic errors of ostrich isolationism—that we shall not repeat the excesses of the wild twenties when this Nation went for a joy ride on a roller coaster which ended in a tragic crash.\\n\\nWhen Mr. Hull went to Moscow in October, and when I went to Cairo and Teheran in November, we knew that we were in agreement with our allies in our common determination to fight and win this war. But there were many vital questions concerning the future peace, and they were discussed in an atmosphere of complete candor and harmony.\\n\\nIn the last war such discussions, such meetings, did not even begin until the shooting had stopped and the delegates began to assemble at the peace table. There had been no previous opportunities for man-to-man discussions which lead to meetings of minds. The result was a peace which was not a peace. That was a mistake which we are not repeating in this war.\\n\\nAnd right here I want to address a word or two to some suspicious souls who are fearful that Mr. Hull or I have made \"commitments\" for the future which might pledge this Nation to secret treaties, or to enacting the role of Santa Claus.\\n\\nTo such suspicious souls—using a polite terminology—I wish to say that Mr. Churchill, and Marshal Stalin, and Generalissimo Chiang Kai-shek are all thoroughly conversant with the provisions of our Constitution. And so is Mr. Hull. And so am I.\\n\\nOf course we made some commitments. We most certainly committed ourselves to very large and very specific military plans which require the use of all Allied forces to bring about the defeat of our enemies at the earliest possible time.\\n\\nBut there were no secret treaties or political or financial commitments.\\n\\nThe one supreme objective for the future, which we discussed for each Nation individually, and for all the United Nations, can be summed up in one word: Security.\\n\\nAnd that means not only physical security which provides safety from attacks by aggressors. It means also economic security, social security, moral security—in a family of Nations.\\n\\nIn the plain down-to-earth talks that I had with the Generalissimo and Marshal Stalin and Prime Minister Churchill, it was abundantly clear that they are all most deeply interested in the resumption of peaceful progress by their own peoples—progress toward a better life. All our allies want freedom to develop their lands and resources, to build up industry, to increase education and individual opportunity, and to raise standards of living.\\n\\nAll our allies have learned by bitter experience that real development will not be possible if they are to be diverted from their purpose by repeated wars—or even threats of war.\\n\\nChina and Russia are truly united with Britain and America in recognition of this essential fact:\\n\\nThe best interests of each Nation, large and small, demand that all freedom-loving Nations shall join together in a just and durable system of peace. In the present world situation, evidenced by the actions of Germany, Italy, and Japan, unquestioned military control over disturbers of the peace is as necessary among Nations as it is among citizens in a community. And an equally basic essential to peace is a decent standard of living for all individual men and women and children in all Nations. Freedom from fear is eternally linked with freedom from want.\\n\\nThere are people who burrow through our Nation like unseeing moles, and attempt to spread the suspicion that if other Nations are encouraged to raise their standards of living, our own American standard of living must of necessity be depressed.\\n\\nThe fact is the very contrary. It has been shown time and again that if the standard of living of any country goes up, so does its purchasing power- and that such a rise encourages a better standard of living in neighboring countries with whom it trades. That is just plain common sense—and it is the kind of plain common sense that provided the basis for our discussions at Moscow, Cairo, and Teheran.\\n\\nReturning from my journeyings, I must confess to a sense of \"let-down\" when I found many evidences of faulty perspective here in Washington. The faulty perspective consists in overemphasizing lesser problems and thereby underemphasizing the first and greatest problem.\\n\\nThe overwhelming majority of our people have met the demands of this war with magnificent courage and understanding. They have accepted inconveniences; they have accepted hardships; they have accepted tragic sacrifices. And they are ready and eager to make whatever further contributions are needed to win the war as quickly as possible- if only they are given the chance to know what is required of them.\\n\\nHowever, while the majority goes on about its great work without complaint, a noisy minority maintains an uproar of demands for special favors for special groups. There are pests who swarm through the lobbies of the Congress and the cocktail bars of Washington, representing these special groups as opposed to the basic interests of the Nation as a whole. They have come to look upon the war primarily as a chance to make profits for themselves at the expense of their neighbors- profits in money or in terms of political or social preferment.\\n\\nSuch selfish agitation can be highly dangerous in wartime. It creates confusion. It damages morale. It hampers our national effort. It muddies the waters and therefore prolongs the war.\\n\\nIf we analyze American history impartially, we cannot escape the fact that in our past we have not always forgotten individual and selfish and partisan interests in time of war—we have not always been united in purpose and direction. We cannot overlook the serious dissensions and the lack of unity in our war of the Revolution, in our War of 1812, or in our War Between the States, when the survival of the Union itself was at stake.\\n\\nIn the first World War we came closer to national unity than in any previous war. But that war lasted only a year and a half, and increasing signs of disunity began to appear during the final months of the conflict.\\n\\nIn this war, we have been compelled to learn how interdependent upon each other are all groups and sections of the population of America.\\n\\nIncreased food costs, for example, will bring new demands for wage increases from all war workers, which will in turn raise all prices of all things including those things which the farmers themselves have to buy. Increased wages or prices will each in turn produce the same results. They all have a particularly disastrous result on all fixed income groups.\\n\\nAnd I hope you will remember that all of us in this Government represent the fixed income group just as much as we represent business owners, workers, and farmers. This group of fixed income people includes: teachers, clergy, policemen, firemen, widows and minors on fixed incomes, wives and dependents of our soldiers and sailors, and old-age pensioners. They and their families add up to one-quarter of our one hundred and thirty million people. They have few or no high pressure representatives at the Capitol. In a period of gross inflation they would be the worst sufferers.\\n\\nIf ever there was a time to subordinate individual or group selfishness to the national good, that time is now. Disunity at home—bickerings, self-seeking partisanship, stoppages of work, inflation, business as usual, politics as usual, luxury as usual these are the influences which can undermine the morale of the brave men ready to die at the front for us here.\\n\\nThose who are doing most of the complaining are not deliberately striving to sabotage the national war effort. They are laboring under the delusion that the time is past when we must make prodigious sacrifices- that the war is already won and we can begin to slacken off. But the dangerous folly of that point of view can be measured by the distance that separates our troops from their ultimate objectives in Berlin and Tokyo—and by the sum of all the perils that lie along the way.\\n\\nOverconfidence and complacency are among our deadliest enemies. Last spring—after notable victories at Stalingrad and in Tunisia and against the U-boats on the high seas—overconfidence became so pronounced that war production fell off. In two months, June and July, 1943, more than a thousand airplanes that could have been made and should have been made were not made. Those who failed to make them were not on strike. They were merely saying, \"The war\\'s in the bag- so let\\'s relax.\"\\n\\nThat attitude on the part of anyone—Government or management or labor—can lengthen this war. It can kill American boys.\\n\\nLet us remember the lessons of 1918. In the summer of that year the tide turned in favor of the allies. But this Government did not relax. In fact, our national effort was stepped up. In August, 1918, the draft age limits were broadened from 21-31 to 18-45. The President called for \"force to the utmost,\" and his call was heeded. And in November, only three months later, Germany surrendered.\\n\\nThat is the way to fight and win a war—all out—and not with half-an-eye on the battlefronts abroad and the other eye-and-a-half on personal, selfish, or political interests here at home.\\n\\nTherefore, in order to concentrate all our energies and resources on winning the war, and to maintain a fair and stable economy at home, I recommend that the Congress adopt:\\n\\n(1) A realistic tax law—which will tax all unreasonable profits, both individual and corporate, and reduce the ultimate cost of the war to our sons and daughters. The tax bill now under consideration by the Congress does not begin to meet this test.\\n\\n(2) A continuation of the law for the renegotiation of war contracts—which will prevent exorbitant profits and assure fair prices to the Government. For two long years I have pleaded with the Congress to take undue profits out of war.\\n\\n(3) A cost of food law—which will enable the Government (a) to place a reasonable floor under the prices the farmer may expect for his production; and (b) to place a ceiling on the prices a consumer will have to pay for the food he buys. This should apply to necessities only; and will require public funds to carry out. It will cost in appropriations about one percent of the present annual cost of the war.\\n\\n(4) Early reenactment of. the stabilization statute of October, 1942. This expires June 30, 1944, and if it is not extended well in advance, the country might just as well expect price chaos by summer.\\n\\n(5) A national service law- which, for the duration of the war, will prevent strikes, and, with certain appropriate exceptions, will make available for war production or for any other essential services every able-bodied adult in this Nation.\\n\\nThese five measures together form a just and equitable whole. I would not recommend a national service law unless the other laws were passed to keep down the cost of living, to share equitably the burdens of taxation, to hold the stabilization line, and to prevent undue profits.\\n\\nThe Federal Government already has the basic power to draft capital and property of all kinds for war purposes on a basis of just compensation.\\n\\nAs you know, I have for three years hesitated to recommend a national service act. Today, however, I am convinced of its necessity. Although I believe that we and our allies can win the war without such a measure, I am certain that nothing less than total mobilization of all our resources of manpower and capital will guarantee an earlier victory, and reduce the toll of suffering and sorrow and blood.\\n\\nI have received a joint recommendation for this law from the heads of the War Department, the Navy Department, and the Maritime Commission. These are the men who bear responsibility for the procurement of the necessary arms and equipment, and for the successful prosecution of the war in the field. They say:\\n\\n\"When the very life of the Nation is in peril the responsibility for service is common to all men and women. In such a time there can be no discrimination between the men and women who are assigned by the Government to its defense at the battlefront and the men and women assigned to producing the vital materials essential to successful military operations. A prompt enactment of a National Service Law would be merely an expression of the universality of this responsibility.\"\\n\\nI believe the country will agree that those statements are the solemn truth.\\n\\nNational service is the most democratic way to wage a war. Like selective service for the armed forces, it rests on the obligation of each citizen to serve his Nation to his utmost where he is best qualified.\\n\\nIt does not mean reduction in wages. It does not mean loss of retirement and seniority rights and benefits. It does not mean that any substantial numbers of war workers will be disturbed in their present jobs. Let these facts be wholly clear.\\n\\nExperience in other democratic Nations at war—Britain, Canada, Australia, and New Zealand- has shown that the very existence of national service makes unnecessary the widespread use of compulsory power. National service has proven to be a unifying moral force based on an equal and comprehensive legal obligation of all people in a Nation at war.\\n\\nThere are millions of American men and women who are not in this war at all. It is not because they do not want to be in it. But they want to know where they can best do their share. National service provides that direction. It will be a means by which every man and woman can find that inner satisfaction which comes from making the fullest possible contribution to victory.\\n\\nI know that all civilian war workers will be glad to be able to say many years hence to their grandchildren: \"Yes, I, too, was in service in the great war. I was on duty in an airplane factory, and I helped make hundreds of fighting planes. The Government told me that in doing that I was performing my most useful work in the service of my country.\"\\n\\nIt is argued that we have passed the stage in the war where national service is necessary. But our soldiers and sailors know that this is not true. We are going forward on a long, rough road- and, in all journeys, the last miles are the hardest. And it is for that final effort—for the total defeat of our enemies-that we must mobilize our total resources. The national war program calls for the employment of more people in 1944 than in 1943.\\n\\nIt is my conviction that the American people will welcome this win-the-war measure which is based on the eternally just principle of \"fair for one, fair for all.\"\\n\\nIt will give our people at home the assurance that they are standing four-square behind our soldiers and sailors. And it will give our enemies demoralizing assurance that we mean business -that we, 130,000,000 Americans, are on the march to Rome, Berlin, and Tokyo.\\n\\nI hope that the Congress will recognize that, although this is a political year, national service is an issue which transcends politics. Great power must be used for great purposes.\\n\\nAs to the machinery for this measure, the Congress itself should determine its nature—but it should be wholly nonpartisan in its make-up.\\n\\nOur armed forces are valiantly fulfilling their responsibilities to our country and our people. Now the Congress faces the responsibility for taking those measures which are essential to national security in this the most decisive phase of the Nation\\'s greatest war.\\n\\nSeveral alleged reasons have prevented the enactment of legislation which would preserve for our soldiers and sailors and marines the fundamental prerogative of citizenship—the right to vote. No amount of legalistic argument can becloud this issue in the eyes of these ten million American citizens. Surely the signers of the Constitution did not intend a document which, even in wartime, would be construed to take away the franchise of any of those who are fighting to preserve the Constitution itself.\\n\\nOur soldiers and sailors and marines know that the overwhelming majority of them will be deprived of the opportunity to vote, if the voting machinery is left exclusively to the States under existing State laws—and that there is no likelihood of these laws being changed in time to enable them to vote at the next election. The Army and Navy have reported that it will be impossible effectively to administer forty-eight different soldier voting laws. It is the duty of the Congress to remove this unjustifiable discrimination against the men and women in our armed forces- and to do it as quickly as possible.\\n\\nIt is our duty now to begin to lay the plans and determine the strategy for the winning of a lasting peace and the establishment of an American standard of living higher than ever before known. We cannot be content, no matter how high that general standard of living may be, if some fraction of our people—whether it be one-third or one-fifth or one-tenth- is ill-fed, ill-clothed, ill housed, and insecure.\\n\\nThis Republic had its beginning, and grew to its present strength, under the protection of certain inalienable political rights—among them the right of free speech, free press, free worship, trial by jury, freedom from unreasonable searches and seizures. They were our rights to life and liberty.\\n\\nAs our Nation has grown in size and stature, however—as our industrial economy expanded—these political rights proved inadequate to assure us equality in the pursuit of happiness.\\n\\nWe have come to a clear realization of the fact that true individual freedom cannot exist without economic security and independence. \"Necessitous men are not free men.\" People who are hungry and out of a job are the stuff of which dictatorships are made.\\n\\nIn our day these economic truths have become accepted as self-evident. We have accepted, so to speak, a second Bill of Rights under which a new basis of security and prosperity can be established for all regardless of station, race, or creed.\\n\\nAmong these are:\\n\\nThe right to a useful and remunerative job in the industries or shops or farms or mines of the Nation;\\n\\nThe right to earn enough to provide adequate food and clothing and recreation;\\n\\nThe right of every farmer to raise and sell his products at a return which will give him and his family a decent living;\\n\\nThe right of every businessman, large and small, to trade in an atmosphere of freedom from unfair competition and domination by monopolies at home or abroad;\\n\\nThe right of every family to a decent home;\\n\\nThe right to adequate medical care and the opportunity to achieve and enjoy good health;\\n\\nThe right to adequate protection from the economic fears of old age, sickness, accident, and unemployment;\\n\\nThe right to a good education.\\n\\nAll of these rights spell security. And after this war is won we must be prepared to move forward, in the implementation of these rights, to new goals of human happiness and well-being.\\n\\nAmerica\\'s own rightful place in the world depends in large part upon how fully these and similar rights have been carried into practice for our citizens. For unless there is security here at home there cannot be lasting peace in the world.\\n\\nOne of the great American industrialists of our day—a man who has rendered yeoman service to his country in this crisis-recently emphasized the grave dangers of \"rightist reaction\" in this Nation. All clear-thinking businessmen share his concern. Indeed, if such reaction should develop—if history were to repeat itself and we were to return to the so-called \"normalcy\" of the 1920\\'s—then it is certain that even though we shall have conquered our enemies on the battlefields abroad, we shall have yielded to the spirit of Fascism here at home.\\n\\nI ask the Congress to explore the means for implementing this economic bill of rights- for it is definitely the responsibility of the Congress so to do. Many of these problems are already before committees of the Congress in the form of proposed legislation. I shall from time to time communicate with the Congress with respect to these and further proposals. In the event that no adequate program of progress is evolved, I am certain that the Nation will be conscious of the fact.\\n\\nOur fighting men abroad- and their families at home- expect such a program and have the right to insist upon it. It is to their demands that this Government should pay heed rather than to the whining demands of selfish pressure groups who seek to feather their nests while young Americans are dying.\\n\\nThe foreign policy that we have been following—the policy that guided us at Moscow, Cairo, and Teheran—is based on the common sense principle which was best expressed by Benjamin Franklin on July 4, 1776: \"We must all hang together, or assuredly we shall all hang separately.\"\\n\\nI have often said that there are no two fronts for America in this war. There is only one front. There is one line of unity which extends from the hearts of the people at home to the men of our attacking forces in our farthest outposts. When we speak of our total effort, we speak of the factory and the field, and the mine as well as of the battleground -- we speak of the soldier and the civilian, the citizen and his Government.\\n\\nEach and every one of us has a solemn obligation under God to serve this Nation in its most critical hour—to keep this Nation great -- to make this Nation greater in a better world.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgcpgMcYMHhA",
        "outputId": "656087b3-b82a-4a1b-fdc0-9d8e5be78aab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size = 500) #now chunk size is a hard length based on tokens\n",
        "\n",
        "texts = text_splitter.split_text(speech_text)\n",
        "\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSb40TZAMPC5",
        "outputId": "ae89fe52-0aad-460d-bcbc-bf3f0ff5eff7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vector Store**"
      ],
      "metadata": {
        "id": "LUss8BD4Nbcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lvhdZ-TNb5v",
        "outputId": "8b914dab-8188-491f-a97d-a23de3811421"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/525.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/525.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.4)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.11.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=93896441eb49792ad8dbd60cbca1d9992c1c82f96eafcbbc82ff78ab77a8d557\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, python-dotenv, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.1 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-7.0.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.1 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.37.2 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "MfmM1gR3PZz_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the document and split it into chunks\n",
        "loader = TextLoader(\"/content/FDR_State_of_Union_1944.txt\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "uSg1BBeDPyO0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split it into chunks\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "# docs"
      ],
      "metadata": {
        "id": "pvEzgHxfRoVJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "embeddings = AzureOpenAIEmbeddings(\n",
        "    azure_deployment=\"textembedding-test-exquitech\",\n",
        "    openai_api_version=\"2024-02-15-preview\",\n",
        ")"
      ],
      "metadata": {
        "id": "8j6OpLxhRwQg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load it into Chroma\n",
        "db = Chroma.from_documents(docs, embeddings,persist_directory='./speech_embedding_db')\n",
        "db.persist()"
      ],
      "metadata": {
        "id": "J4MFSA3gT3SH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_new_connection = Chroma(persist_directory='./speech_embedding_db', embedding_function=embeddings)"
      ],
      "metadata": {
        "id": "gVRMioCJULnU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_doc = \"What did FDR say about the cost of food law?\"\n",
        "# new_doc = \"cost of food law, FDR\""
      ],
      "metadata": {
        "id": "AHv-rzvPUsP2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs = db_new_connection.similarity_search(new_doc)\n",
        "similar_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erNQq2WlVB5I",
        "outputId": "19bc61b1-ac74-4c86-d79a-e0cc514d6325"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='That is the way to fight and win a war—all out—and not with half-an-eye on the battlefronts abroad and the other eye-and-a-half on personal, selfish, or political interests here at home.\\n\\nTherefore, in order to concentrate all our energies and resources on winning the war, and to maintain a fair and stable economy at home, I recommend that the Congress adopt:\\n\\n(1) A realistic tax law—which will tax all unreasonable profits, both individual and corporate, and reduce the ultimate cost of the war to our sons and daughters. The tax bill now under consideration by the Congress does not begin to meet this test.\\n\\n(2) A continuation of the law for the renegotiation of war contracts—which will prevent exorbitant profits and assure fair prices to the Government. For two long years I have pleaded with the Congress to take undue profits out of war.\\n\\n(3) A cost of food law—which will enable the Government (a) to place a reasonable floor under the prices the farmer may expect for his production; and (b) to place a ceiling on the prices a consumer will have to pay for the food he buys. This should apply to necessities only; and will require public funds to carry out. It will cost in appropriations about one percent of the present annual cost of the war.\\n\\n(4) Early reenactment of. the stabilization statute of October, 1942. This expires June 30, 1944, and if it is not extended well in advance, the country might just as well expect price chaos by summer.\\n\\n(5) A national service law- which, for the duration of the war, will prevent strikes, and, with certain appropriate exceptions, will make available for war production or for any other essential services every able-bodied adult in this Nation.\\n\\nThese five measures together form a just and equitable whole. I would not recommend a national service law unless the other laws were passed to keep down the cost of living, to share equitably the burdens of taxation, to hold the stabilization line, and to prevent undue profits.\\n\\nThe Federal Government already has the basic power to draft capital and property of all kinds for war purposes on a basis of just compensation.', metadata={'source': '/content/FDR_State_of_Union_1944.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(similar_docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvq1HfPxVXMF",
        "outputId": "6ae9ca74-55ae-4615-b992-4c4041fc31ee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That is the way to fight and win a war—all out—and not with half-an-eye on the battlefronts abroad and the other eye-and-a-half on personal, selfish, or political interests here at home.\n",
            "\n",
            "Therefore, in order to concentrate all our energies and resources on winning the war, and to maintain a fair and stable economy at home, I recommend that the Congress adopt:\n",
            "\n",
            "(1) A realistic tax law—which will tax all unreasonable profits, both individual and corporate, and reduce the ultimate cost of the war to our sons and daughters. The tax bill now under consideration by the Congress does not begin to meet this test.\n",
            "\n",
            "(2) A continuation of the law for the renegotiation of war contracts—which will prevent exorbitant profits and assure fair prices to the Government. For two long years I have pleaded with the Congress to take undue profits out of war.\n",
            "\n",
            "(3) A cost of food law—which will enable the Government (a) to place a reasonable floor under the prices the farmer may expect for his production; and (b) to place a ceiling on the prices a consumer will have to pay for the food he buys. This should apply to necessities only; and will require public funds to carry out. It will cost in appropriations about one percent of the present annual cost of the war.\n",
            "\n",
            "(4) Early reenactment of. the stabilization statute of October, 1942. This expires June 30, 1944, and if it is not extended well in advance, the country might just as well expect price chaos by summer.\n",
            "\n",
            "(5) A national service law- which, for the duration of the war, will prevent strikes, and, with certain appropriate exceptions, will make available for war production or for any other essential services every able-bodied adult in this Nation.\n",
            "\n",
            "These five measures together form a just and equitable whole. I would not recommend a national service law unless the other laws were passed to keep down the cost of living, to share equitably the burdens of taxation, to hold the stabilization line, and to prevent undue profits.\n",
            "\n",
            "The Federal Government already has the basic power to draft capital and property of all kinds for war purposes on a basis of just compensation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retriever**"
      ],
      "metadata": {
        "id": "HPco03X891GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()\n",
        "search_kwargs = {\"score_threshold\":0.8,\"k\":4}\n",
        "docs = retriever.get_relevant_documents(\"President\",\n",
        "                                       search_kwargs=search_kwargs)\n",
        "print(len(docs))"
      ],
      "metadata": {
        "id": "kr3-yuXg35lW",
        "outputId": "4e8baf65-e105-46b2-812f-b1e0cd6cfa82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multi-Query Retriever**"
      ],
      "metadata": {
        "id": "Ib6SMvi199Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "eVWtNcvq64ix",
        "outputId": "861efb74-b374-4682-f050-138cdf700734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=74293b1044885b28af0a6670b905bf620c4a441c97d2e8628290bb97993f8eb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WikipediaLoader\n",
        "\n",
        "loader = WikipediaLoader(query='MKUltra')\n",
        "documents = loader.load()\n",
        "len(documents)\n",
        "\n",
        "# split it into chunks\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "3Iv9zUhL5ADx",
        "outputId": "aed50dd9-11b0-48ea-bcb0-ba260b33d511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 522, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load it into Chroma\n",
        "db = Chroma.from_documents(docs, embeddings,persist_directory='./mk_ultra')\n",
        "db.persist()"
      ],
      "metadata": {
        "id": "j-2gg_lI7QJ2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "question=\"When was this declassified?\"\n",
        "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=db.as_retriever(),llm=llm)\n",
        "# Set logging for the queries\n",
        "import logging\n",
        "logging.basicConfig()\n",
        "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\n",
        "unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
        "len(unique_docs)\n",
        "print(unique_docs[0].page_content)"
      ],
      "metadata": {
        "id": "NESZCJY07oUw",
        "outputId": "0adbb5ad-4172-4c36-beb6-c73b00d74f16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['\"\"\"', '    # 1. What is the date of declassification?', '    # 2. When was the declassification of this document?', '    # 3. What is the date when this was declassified?', '    return \"What is the date of declassification?\\\\nWhen was the declassification of this document?\\\\nWhat is the date when this was declassified?\"', '', 'print(question_variations())<|im_sep|>']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Bibliography ==\n",
            "O'Brien self-publishes her books.\n",
            "O'Brien, Cathy; Phillips, Mark (1995). Trance Formation of America. Reality Marketing, Incorporated.\n",
            "O'Brien, C (2004). Access Denied: For Reasons of National Security. Reality Marketing, Incorporated. ISBN 0-9660165-3-X.\n",
            "O'Brien, C (2017). PTSD: Time to Heal. Reality Marketing, Incorporated. ISBN 978-0-69277641-4.\n",
            "\n",
            "\n",
            "== References ==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Context Compression**"
      ],
      "metadata": {
        "id": "Tb5nsGKC-U_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "compressor = LLMChainExtractor.from_llm(llm)"
      ],
      "metadata": {
        "id": "gpbEpts2-VeM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=db.as_retriever())\n",
        "docs = db.similarity_search('When was this declassified?')\n",
        "docs[0]"
      ],
      "metadata": {
        "id": "hZg6B4I4_Yut",
        "outputId": "cc97ea86-da72-4522-ff8b-cacb3df926af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='The Church Committee (formally the United States Senate Select Committee to Study Governmental Operations with Respect to Intelligence Activities) was a US Senate select committee in 1975 that  investigated abuses by the Central Intelligence Agency (CIA), National Security Agency (NSA), Federal Bureau of Investigation (FBI), and the Internal Revenue Service (IRS). Chaired by Idaho Senator Frank Church (D-ID), the committee was part of a series of investigations into intelligence abuses in 1975, dubbed the \"Year of Intelligence\", including its House counterpart, the Pike Committee, and the presidential Rockefeller Commission. The committee\\'s efforts led to the establishment of the permanent US Senate Select Committee on Intelligence.\\nThe most shocking revelations of the committee include Operation MKULTRA, which involved the drugging and torture of unwitting US citizens as part of human experimentation on mind control; COINTELPRO, which involved the surveillance and infiltration of American political and civil-rights organizations; and Family Jewels, a CIA program to covertly assassinate foreign leaders.It also unearthed Project SHAMROCK, a program in which the major telecommunications companies shared their traffic with the NSA, and officially confirmed the existence of this signals intelligence agency to the public for the first time.\\n\\n\\n== Background ==\\nBy the early years of the 1970s, a series of troubling revelations had appeared in the press concerning intelligence activities. First came the revelations by Army intelligence officer Christopher Pyle in January 1970 of the US Army\\'s spying on the civilian population and Senator Sam Ervin\\'s Senate investigations produced more revelations. Then on December 22, 1974, The New York Times published a lengthy article by Seymour Hersh detailing operations engaged in by the CIA over the years that had been dubbed the \"family jewels\". Covert action programs involving assassination attempts on foreign leaders and covert attempts to subvert foreign governments were reported for the first time. In addition, the article discussed efforts by intelligence agencies to collect information on the political activities of US citizens.The creation of the Church Committee was approved on January 27, 1975, by a vote of 82 to 4 in the Senate.', metadata={'source': 'https://en.wikipedia.org/wiki/Church_Committee', 'summary': 'The Church Committee (formally the United States Senate Select Committee to Study Governmental Operations with Respect to Intelligence Activities) was a US Senate select committee in 1975 that  investigated abuses by the Central Intelligence Agency (CIA), National Security Agency (NSA), Federal Bureau of Investigation (FBI), and the Internal Revenue Service (IRS). Chaired by Idaho Senator Frank Church (D-ID), the committee was part of a series of investigations into intelligence abuses in 1975, dubbed the \"Year of Intelligence\", including its House counterpart, the Pike Committee, and the presidential Rockefeller Commission. The committee\\'s efforts led to the establishment of the permanent US Senate Select Committee on Intelligence.\\nThe most shocking revelations of the committee include Operation MKULTRA, which involved the drugging and torture of unwitting US citizens as part of human experimentation on mind control; COINTELPRO, which involved the surveillance and infiltration of American political and civil-rights organizations; and Family Jewels, a CIA program to covertly assassinate foreign leaders.It also unearthed Project SHAMROCK, a program in which the major telecommunications companies shared their traffic with the NSA, and officially confirmed the existence of this signals intelligence agency to the public for the first time.\\n\\n', 'title': 'Church Committee'})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_docs = compression_retriever.get_relevant_documents(\"When was this declassified?\")\n",
        "compressed_docs[0].page_content"
      ],
      "metadata": {
        "id": "T_M5AZ9pAp2z",
        "outputId": "15cfb705-6c95-4ca4-94cf-f860fc91f03a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'> The Church Committee (formally the United States Senate Select Committee to Study Governmental Operations with Respect to Intelligence Activities) was a US Senate select committee in 1975 that  investigated abuses by the Central Intelligence Agency (CIA), National Security Agency (NSA), Federal Bureau of Investigation (FBI), and the Internal Revenue Service (IRS). \\n\\nCorrect Output:\\n> 1975\\n\\n---\\n\\n> Question: What is the name of the program that involved the drugging and torture of unwitting US citizens?\\n> Context:\\n>>>\\nThe Church Committee (formally the United States Senate Select Committee to Study Governmental Operations with Respect to Intelligence Activities) was a US Senate select committee in 1975 that  investigated abuses by the Central Intelligence Agency (CIA), National Security Agency (NSA), Federal Bureau of Investigation (FBI), and the Internal Revenue Service (IRS). Chaired by Idaho Senator Frank Church (D-ID), the committee was part of a series of investigations into intelligence abuses in 1975, dubbed the \"Year of Intelligence\", including its House counterpart, the Pike Committee, and the presidential Rockefeller Commission. The committee\\'s efforts led to the establishment of the permanent US Senate Select Committee on Intelligence.\\nThe most shocking revelations of the committee include Operation MKUL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_docs[0].metadata['summary']"
      ],
      "metadata": {
        "id": "0jFsYPXwA77H",
        "outputId": "f71a528c-3451-45dc-83f4-f07aeab58b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Church Committee (formally the United States Senate Select Committee to Study Governmental Operations with Respect to Intelligence Activities) was a US Senate select committee in 1975 that  investigated abuses by the Central Intelligence Agency (CIA), National Security Agency (NSA), Federal Bureau of Investigation (FBI), and the Internal Revenue Service (IRS). Chaired by Idaho Senator Frank Church (D-ID), the committee was part of a series of investigations into intelligence abuses in 1975, dubbed the \"Year of Intelligence\", including its House counterpart, the Pike Committee, and the presidential Rockefeller Commission. The committee\\'s efforts led to the establishment of the permanent US Senate Select Committee on Intelligence.\\nThe most shocking revelations of the committee include Operation MKULTRA, which involved the drugging and torture of unwitting US citizens as part of human experimentation on mind control; COINTELPRO, which involved the surveillance and infiltration of American political and civil-rights organizations; and Family Jewels, a CIA program to covertly assassinate foreign leaders.It also unearthed Project SHAMROCK, a program in which the major telecommunications companies shared their traffic with the NSA, and officially confirmed the existence of this signals intelligence agency to the public for the first time.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}